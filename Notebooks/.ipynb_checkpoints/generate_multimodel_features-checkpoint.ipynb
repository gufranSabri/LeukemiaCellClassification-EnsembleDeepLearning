{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "644d91a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '12'\n",
    "\n",
    "import tensorflow as tf\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e2be8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_src_path = r'C:\\Users\\gufra\\Desktop\\Work\\Projects\\AI\\ALL_Classification\\Datasets\\Original'\n",
    "data_dst_path = r'C:\\Users\\gufra\\Desktop\\Work\\Projects\\AI\\ALL_Classification\\Datasets\\CSV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88716bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(model_name, img):\n",
    "    if model_name == 'mobilenetv2': return np.expand_dims(tf.keras.applications.mobilenet_v2.preprocess_input(img),axis=0)\n",
    "    if model_name == 'resnet101': return np.expand_dims(tf.keras.applications.resnet.preprocess_input(img),axis=0)\n",
    "    if model_name == 'vgg16': return np.expand_dims(tf.keras.applications.vgg16.preprocess_input(img),axis=0)\n",
    "    if model_name == 'vgg19': return np.expand_dims(tf.keras.applications.vgg19.preprocess_input(img),axis=0)\n",
    "    if model_name == 'inceptionresnetv2': return np.expand_dims(tf.keras.applications.inception_resnet_v2.preprocess_input(img),axis=0)\n",
    "    if model_name == 'densenet': return np.expand_dims(tf.keras.applications.densenet.preprocess_input(img),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cba9c0d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "mbase = tf.keras.applications.MobileNetV2(input_shape=(450, 450, 3),include_top=False, weights='imagenet')\n",
    "mbase.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eddef3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbase = tf.keras.applications.ResNet101(input_shape=(450, 450, 3), include_top=False, weights=\"imagenet\")\n",
    "rbase.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad81b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "v16base = tf.keras.applications.VGG16(input_shape=(450, 450, 3),include_top=False, weights='imagenet')\n",
    "v16base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79526db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "v19base = tf.keras.applications.VGG19(input_shape=(450, 450, 3),include_top=False, weights='imagenet')\n",
    "v19base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ccc2e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "ibase = tf.keras.applications.InceptionResNetV2(input_shape=(450, 450, 3),include_top=False, weights='imagenet')\n",
    "ibase.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6506547",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbase = tf.keras.applications.DenseNet121(input_shape=(450, 450, 3),include_top=False, weights='imagenet')\n",
    "dbase.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69b8510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetv2 = tf.keras.models.Model(\n",
    "    inputs=mbase.input, \n",
    "    outputs=tf.keras.layers.GlobalAveragePooling2D()(mbase.output)\n",
    ")\n",
    "resnet101 = tf.keras.models.Model(\n",
    "    inputs=rbase.input, \n",
    "    outputs= tf.keras.layers.GlobalAveragePooling2D()(rbase.output)\n",
    ")\n",
    "vgg16 = tf.keras.models.Model(\n",
    "    inputs=v16base.input, \n",
    "    outputs= tf.keras.layers.GlobalAveragePooling2D()(v16base.output)\n",
    ")\n",
    "vgg19 = tf.keras.models.Model(\n",
    "    inputs=v19base.input, \n",
    "    outputs= tf.keras.layers.GlobalAveragePooling2D()(v19base.output)\n",
    ")\n",
    "inceptionresnetv2 = tf.keras.models.Model(\n",
    "    inputs=ibase.input, \n",
    "    outputs= tf.keras.layers.GlobalAveragePooling2D()(ibase.output)\n",
    ")\n",
    "densenet = tf.keras.models.Model(\n",
    "    inputs=dbase.input, \n",
    "    outputs= tf.keras.layers.GlobalAveragePooling2D()(dbase.output)\n",
    ")\n",
    "\n",
    "models = [mobilenetv2, resnet101, vgg16, vgg19, inceptionresnetv2, densenet]\n",
    "model_names = [\"mobilenetv2\", \"resnet101\", \"vgg16\", \"vgg19\", \"inceptionresnetv2\", \"densenet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10073927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 807ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E7AF7F39A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E7FF62C9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1280, 2048, 512, 512, 1536, 1024]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(r\"C:\\Users\\gufra\\Desktop\\Work\\Projects\\AI\\ALL_Classification\\Datasets\\Original\\all\\UID_1_1_1_all.bmp\")\n",
    "\n",
    "mobilenetv2_num_ftrs = len(mobilenetv2.predict(preprocess(\"mobilenetv2\",img)).flatten())\n",
    "resnet101_num_ftrs = len(resnet101.predict(preprocess(\"resnet101\",img)).flatten())\n",
    "vgg16_num_ftrs = len(vgg16.predict(preprocess(\"vgg16\",img)).flatten())\n",
    "vgg19_num_ftrs = len(vgg19.predict(preprocess(\"vgg19\",img)).flatten())\n",
    "inceptionresnetv2_num_ftrs = len(inceptionresnetv2.predict(preprocess(\"inceptionresnetv2\",img)).flatten())\n",
    "densenet_num_ftrs = len(densenet.predict(preprocess(\"densenet\",img)).flatten())\n",
    "\n",
    "num_features = [mobilenetv2_num_ftrs, resnet101_num_ftrs, vgg16_num_ftrs, vgg19_num_ftrs, inceptionresnetv2_num_ftrs, densenet_num_ftrs]\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1043c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points_straight(img, line_coord, limit, dir):\n",
    "        first, last=None,None\n",
    "        for i in range(limit):\n",
    "            if dir == 1:\n",
    "                if img[line_coord][i] == 0:\n",
    "                    if first==None:first = [line_coord, i]\n",
    "                    else: last = [line_coord, i]\n",
    "            else:\n",
    "                if img[i][line_coord] == 0:\n",
    "                    if first==None:first= [i, line_coord]\n",
    "                    else: last = [i, line_coord]\n",
    "        return [first,last]\n",
    "\n",
    "def diag_traverser(img, x, y, get_points, dir):\n",
    "    first, last = None, None\n",
    "    count = 0\n",
    "\n",
    "    i,j=x,y\n",
    "    while True:\n",
    "        try:\n",
    "            if i<0 or j<0:break\n",
    "            if img[i,j] == 0:\n",
    "                if first==None:first= [j,i]\n",
    "                else: last = [j,i]\n",
    "                count+=1\n",
    "\n",
    "            i+=1\n",
    "            if dir==1: j+=1\n",
    "            else: j-=1\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    if get_points:return [first,last]\n",
    "    return count\n",
    "\n",
    "def get_distance(point1, point2):\n",
    "    if point1==None or point2==None:return -1\n",
    "    return math.dist(point1,point2)\n",
    "\n",
    "def get_distance_between_centers(line1_points, line2_points):\n",
    "    point11, point12 = line1_points[0], line1_points[1]\n",
    "    point21, point22 = line2_points[0], line2_points[1]\n",
    "\n",
    "    if None in [point11, point12, point21, point22]: return -1\n",
    "\n",
    "    line1_center = [(point11[0] + point12[0])/2, (point11[1] + point12[1])/2]\n",
    "    line2_center = [(point21[0] + point22[0])/2, (point21[1] + point22[1])/2]\n",
    "\n",
    "    return get_distance(line1_center, line2_center)\n",
    "\n",
    "def get_structural_features(img):\n",
    "    bw = cv2.Canny(img, 100, 200)\n",
    "    bw = cv2.bitwise_not(bw)\n",
    "\n",
    "    h,w = bw.shape\n",
    "    cropped = bw[:,40:w-40]\n",
    "    h,w = cropped.shape\n",
    "\n",
    "    partition_offset_x = w//4\n",
    "    partition_offset_y = h//4\n",
    "    line1_x = partition_offset_x\n",
    "    line2_x = partition_offset_x*2\n",
    "    line3_x = partition_offset_x*3\n",
    "    line1_y = partition_offset_y\n",
    "    line2_y = partition_offset_y*2\n",
    "    line3_y = partition_offset_y*3\n",
    "\n",
    "    points_hor1 = get_points_straight(cropped, line1_y, w, 1)\n",
    "    points_hor2 = get_points_straight(cropped, line2_y, w, 1)\n",
    "    points_hor3 = get_points_straight(cropped, line3_y, w, 1)\n",
    "    points_ver1 = get_points_straight(cropped, line1_x, h, 2)\n",
    "    points_ver2 = get_points_straight(cropped, line2_x, h, 2)\n",
    "    points_ver3 = get_points_straight(cropped, line3_x, h, 2)\n",
    "    points_diag11 = diag_traverser(cropped, 0, 0, True, 1)\n",
    "    points_diag12 = diag_traverser(cropped, 0, w//2, True, 1)\n",
    "    points_diag13 = diag_traverser(cropped, h//2, 0, True, 1)\n",
    "    points_diag21 = diag_traverser(cropped, 0,w-1, True, 2)\n",
    "    points_diag22 = diag_traverser(cropped, 0,w//2, True, 2)\n",
    "    points_diag23 = diag_traverser(cropped, h//2,w-1, True, 2)\n",
    "\n",
    "    disth1 = get_distance(points_hor1[0],points_hor1[1])\n",
    "    disth2 = get_distance(points_hor2[0],points_hor2[1])\n",
    "    disth3 = get_distance(points_hor3[0],points_hor3[1])\n",
    "    distv1 = get_distance(points_ver1[0],points_ver1[1])\n",
    "    distv2 = get_distance(points_ver2[0],points_ver2[1])\n",
    "    distv3 = get_distance(points_ver3[0],points_ver3[1])\n",
    "    distd11 = get_distance(points_diag11[0],points_diag11[1])\n",
    "    distd12 = get_distance(points_diag12[0],points_diag12[1])\n",
    "    distd13 = get_distance(points_diag13[0],points_diag13[1])\n",
    "    distd21 = get_distance(points_diag21[0],points_diag21[1])\n",
    "    distd22 = get_distance(points_diag22[0],points_diag22[1])\n",
    "    distd23 = get_distance(points_diag23[0],points_diag23[1])\n",
    "\n",
    "    cbp_11 = diag_traverser(cropped, 0, 0, False, 1)\n",
    "    cbp_12 = diag_traverser(cropped, 0, w//2, False, 1)\n",
    "    cbp_13 = diag_traverser(cropped, h//2, 0, False, 1)\n",
    "    cbp_21 = diag_traverser(cropped, 0, w-1, False, 2)\n",
    "    cbp_22 = diag_traverser(cropped, 0, w//2, False, 2)\n",
    "    cbp_23 = diag_traverser(cropped, h//2, w-1, False, 2)\n",
    "\n",
    "    block_counts = []\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            block_cropped = cropped[partition_offset_x*i: partition_offset_x*(i+1), partition_offset_y*j: partition_offset_y*(j+1)]\n",
    "            block_counts.append(np.count_nonzero(block_cropped==0))\n",
    "\n",
    "    distc1 = get_distance_between_centers(points_hor1, points_ver3)\n",
    "    distc2 = get_distance_between_centers(points_hor2, points_ver2)\n",
    "    distc3 = get_distance_between_centers(points_hor3, points_ver1)\n",
    "    distc4 = get_distance_between_centers(points_diag11, points_diag21)\n",
    "    distc5 = get_distance_between_centers(points_diag12, points_diag23)\n",
    "    distc6 = get_distance_between_centers(points_diag13, points_diag22)\n",
    "\n",
    "    count = np.count_nonzero(img==0)\n",
    "\n",
    "    data = []\n",
    "    data.append(points_hor1[0][1] if (points_hor1[0] is not None) else -1)\n",
    "    data.append(points_hor2[0][1] if (points_hor2[0] is not None) else -1)\n",
    "    data.append(points_hor3[0][1] if (points_hor3[0] is not None) else -1)\n",
    "    data.append(points_ver1[0][0] if (points_ver1[0] is not None) else -1)\n",
    "    data.append(points_ver2[0][0] if (points_ver2[0] is not None) else -1)\n",
    "    data.append(points_ver3[0][0] if (points_ver3[0] is not None) else -1)\n",
    "    data.append(points_hor1[1][1] if (points_hor1[1] is not None) else -1)\n",
    "    data.append(points_hor2[1][1] if (points_hor2[1] is not None) else -1)\n",
    "    data.append(points_hor3[1][1] if (points_hor3[1] is not None) else -1)\n",
    "    data.append(points_ver1[1][0] if (points_ver1[1] is not None) else -1)\n",
    "    data.append(points_ver2[1][0] if (points_ver2[1] is not None) else -1)\n",
    "    data.append(points_ver3[1][0] if (points_ver3[1] is not None) else -1) #12\n",
    "\n",
    "    data.append(points_diag11[0][0] if (points_diag11[0] is not None) else -1)\n",
    "    data.append(points_diag12[0][0] if (points_diag12[0] is not None) else -1)\n",
    "    data.append(points_diag13[0][0] if (points_diag13[0] is not None) else -1)\n",
    "    data.append(points_diag21[0][1] if (points_diag21[0] is not None) else -1)\n",
    "    data.append(points_diag22[0][1] if (points_diag22[0] is not None) else -1)\n",
    "    data.append(points_diag23[0][1] if (points_diag23[0] is not None) else -1)\n",
    "    data.append(points_diag11[1][0] if (points_diag11[1] is not None) else -1)\n",
    "    data.append(points_diag12[1][0] if (points_diag12[1] is not None) else -1)\n",
    "    data.append(points_diag13[1][0] if (points_diag13[1] is not None) else -1)\n",
    "    data.append(points_diag21[1][1] if (points_diag21[1] is not None) else -1)\n",
    "    data.append(points_diag22[1][1] if (points_diag22[1] is not None) else -1)\n",
    "    data.append(points_diag23[1][1] if (points_diag23[1] is not None) else -1) #24\n",
    "\n",
    "    data.append(disth1)\n",
    "    data.append(disth2)\n",
    "    data.append(disth3)\n",
    "    data.append(distv1)\n",
    "    data.append(distv2)\n",
    "    data.append(distv3) #30\n",
    "\n",
    "    data.append(distd11)\n",
    "    data.append(distd12)\n",
    "    data.append(distd13)\n",
    "    data.append(distd21)\n",
    "    data.append(distd22)\n",
    "    data.append(distd23) #36\n",
    "\n",
    "    data.append(cbp_11)\n",
    "    data.append(cbp_12)\n",
    "    data.append(cbp_13)\n",
    "    data.append(cbp_21)\n",
    "    data.append(cbp_22)\n",
    "    data.append(cbp_23) #42\n",
    "\n",
    "    data = data + block_counts #58\n",
    "\n",
    "    data.append(distc1)\n",
    "    data.append(distc2)\n",
    "    data.append(distc3)\n",
    "    data.append(distc4)\n",
    "    data.append(distc5)\n",
    "    data.append(distc6) #64\n",
    "\n",
    "    data.append(count) #65\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4be68463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab_features(img):\n",
    "    lab_img = rgb2lab(img)\n",
    "    segments = slic(lab_img, n_segments=3000, compactness=10, sigma=1, start_label=1)\n",
    "\n",
    "    pixelIdxList = [[] for _ in range(np.max(segments)+1)]\n",
    "    for i in range(segments.shape[0]):\n",
    "        for j in range(segments.shape[1]):\n",
    "            pixelIdxList[segments[i,j]].append((i,j))\n",
    "    \n",
    "    mean_colors = np.zeros((np.max(segments)+1,3),dtype='float')\n",
    "    for i in range(np.max(segments)+1):\n",
    "        pixels = pixelIdxList[i]\n",
    "        pixels = np.array(pixels)\n",
    "        if pixels.size>0:\n",
    "            pixels_lab = lab_img[pixels[:,0],pixels[:,1],:]\n",
    "            mean_colors[i,0] = np.mean(pixels_lab[:,0])\n",
    "            mean_colors[i,1] = np.mean(pixels_lab[:,1])\n",
    "            mean_colors[i,2] = np.mean(pixels_lab[:,2])\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=25, n_init=2).fit(mean_colors)\n",
    "    centers_lab = kmeans.cluster_centers_\n",
    "    centers = centers_lab.reshape((1, -1))\n",
    "\n",
    "    return centers.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "098e3aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_feature_extractor(model_indices, include_lab):\n",
    "    splits = os.listdir(data_src_path)\n",
    "    csvs = os.listdir(data_dst_path)\n",
    "\n",
    "    t=time.time()\n",
    "\n",
    "    df = None\n",
    "    for s in splits:\n",
    "        if df is None:\n",
    "            sum_num_features = 0\n",
    "            for mi in model_indices:\n",
    "                sum_num_features+=num_features[mi]\n",
    "            \n",
    "            if include_lab: sum_num_features+=75\n",
    "            cols = [\"f\"+str(n) for n in range(sum_num_features)]\n",
    "            cols.append(\"class\")\n",
    "            df = pd.DataFrame(columns=cols)\n",
    "\n",
    "        print(f\"Processing {s}\")\n",
    "\n",
    "        curr_path = os.path.join(data_src_path, s)\n",
    "        images = os.listdir(curr_path)\n",
    "\n",
    "        c = 0\n",
    "        for img in images:\n",
    "            img = cv2.imread(os.path.join(curr_path,img))\n",
    "            \n",
    "            features = []\n",
    "            for mi in model_indices:\n",
    "                features.append(models[mi].predict(preprocess(model_names[mi], img.copy()),verbose=0).flatten())\n",
    "            \n",
    "            if include_lab: features.append(lab_features(img.copy()))\n",
    "            concatenated_features = tf.keras.layers.Concatenate()(features)\n",
    "            concatenated_features = list(concatenated_features)+[1 if s==\"all\" else 0]\n",
    "            concatenated_features = [float(num) for num in concatenated_features]\n",
    "\n",
    "            row = pd.DataFrame([concatenated_features], columns=cols)\n",
    "            df = pd.concat([df, row], ignore_index=True)\n",
    "\n",
    "            c+=1\n",
    "            if c%100==0:print(c,end=' ')\n",
    "\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    mns = [name for name in model_names if model_names.index(name) in model_indices]\n",
    "    df.to_csv(os.path.join(data_dst_path,f\"{'_'.join(mns)}.csv\"), index=False)\n",
    "    print((time.time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "437c9efa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing all\n",
      "100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400 4500 4600 4700 4800 4900 5000 5100 5200 5300 5400 5500 5600 5700 5800 5900 6000 6100 6200 6300 6400 6500 6600 6700 6800 6900 7000 7100 7200 \n",
      "\n",
      "Processing hem\n",
      "100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 \n",
      "\n",
      "4033.155663728714\n"
     ]
    }
   ],
   "source": [
    "cnn_feature_extractor([0], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dee3c22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing all\n",
      "100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400 4500 4600 4700 4800 4900 5000 5100 5200 5300 5400 5500 5600 5700 5800 5900 6000 6100 6200 6300 6400 6500 6600 6700 6800 6900 7000 7100 7200 \n",
      "\n",
      "Processing hem\n",
      "100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 \n",
      "\n",
      "5547.4913737773895\n"
     ]
    }
   ],
   "source": [
    "cnn_feature_extractor([1], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce068d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing all\n",
      "100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400 4500 4600 4700 4800 4900 5000 5100 5200 5300 5400 5500 5600 5700 5800 5900 6000 6100 6200 6300 6400 6500 6600 6700 6800 6900 7000 7100 7200 \n",
      "\n",
      "Processing hem\n",
      "100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 \n",
      "\n",
      "2588.513947248459\n"
     ]
    }
   ],
   "source": [
    "cnn_feature_extractor([2], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "286743ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing all\n",
      "100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400 4500 4600 4700 4800 4900 5000 5100 5200 5300 5400 5500 5600 5700 5800 5900 6000 6100 6200 6300 6400 6500 6600 6700 6800 6900 7000 7100 7200 \n",
      "\n",
      "Processing hem\n",
      "100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 \n",
      "\n",
      "2259.0196425914764\n"
     ]
    }
   ],
   "source": [
    "cnn_feature_extractor([3], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fc6ac07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing all\n",
      "100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400 4500 4600 4700 4800 4900 5000 5100 5200 5300 5400 5500 5600 5700 5800 5900 6000 6100 6200 6300 6400 6500 6600 6700 6800 6900 7000 7100 7200 \n",
      "\n",
      "Processing hem\n",
      "100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 \n",
      "\n",
      "4518.131747245789\n"
     ]
    }
   ],
   "source": [
    "cnn_feature_extractor([4], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f92cf2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing all\n",
      "100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400 4500 4600 4700 4800 4900 5000 5100 5200 5300 5400 5500 5600 5700 5800 5900 6000 6100 6200 6300 6400 6500 6600 6700 6800 6900 7000 7100 7200 \n",
      "\n",
      "Processing hem\n",
      "100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 \n",
      "\n",
      "3555.6803567409515\n"
     ]
    }
   ],
   "source": [
    "cnn_feature_extractor([5], False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
